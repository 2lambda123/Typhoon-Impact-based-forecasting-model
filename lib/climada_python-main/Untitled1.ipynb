{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24 22:06:31,069 - climada - DEBUG - Loading default config file: C:\\Users\\ATeklesadik\\OneDrive - Rode Kruis\\Documents\\documents\\climada\\climada_python-main\\climada\\conf\\defaults.conf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file is part of CLIMADA.\n",
    "\n",
    "Copyright (C) 2017 CLIMADA contributors listed in AUTHORS.\n",
    "\n",
    "CLIMADA is free software: you can redistribute it and/or modify it under the\n",
    "terms of the GNU Lesser General Public License as published by the Free\n",
    "Software Foundation, version 3.\n",
    "\n",
    "CLIMADA is distributed in the hope that it will be useful, but WITHOUT ANY\n",
    "WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n",
    "PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Lesser General Public License along\n",
    "with CLIMADA. If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "---\n",
    "\n",
    "Define RiverFlood class.\n",
    "\"\"\"\n",
    "\n",
    "__all__ = ['RiverFlood']\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from rasterio.warp import Resampling\n",
    "import copy\n",
    "from climada.util.constants import RIVER_FLOOD_REGIONS_CSV\n",
    "from climada.util.coordinates import get_region_gridpoints,\\\n",
    "                                     region2isos, country_iso2natid\n",
    "from climada.hazard.base import Hazard\n",
    "from climada.hazard.centroids import Centroids\n",
    "from climada.util.coordinates import get_land_geometry, read_raster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hazard type acronym Drought'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "__all__ = ['Drought']\n",
    "\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from climada.hazard.base import Hazard\n",
    "#from climada.hazard.tag import Tag as TagHazard\n",
    "\n",
    "from climada.util.files_handler import download_file\n",
    "from climada.util.dates_times import datetime64_to_ordinal\n",
    "from climada.util.constants import DATA_DIR\n",
    "from climada.util.dates_times import str_to_date\n",
    "from climada.util.dates_times import date_to_str\n",
    "\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "DFL_THRESHOLD = -1\n",
    "DFL_INTENSITY_DEF = 1\n",
    "\n",
    "\n",
    "SPEI_FILE_URL = r'http://digital.csic.es/bitstream/10261/153475/8'\n",
    "SPEI_FILE_DIR = os.path.join(DATA_DIR, 'system')\n",
    "SPEI_FILE_NAME = r'spei06.nc'\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "LATMIN = 44.5\n",
    "LATMAX = 50\n",
    "LONMIN = 5\n",
    "LONMAX = 12\n",
    "\n",
    "\n",
    "HAZ_TYPE = 'DR'\n",
    "\"\"\"Hazard type acronym Drought\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec_list = [[['tcan_nwp','tctr_nwp'],['etctr_nwp'],['etctr_nwp'],['etctr_nwp']],\n",
    "                   [['all_glo']],[['etctr_glo']],[['etctr_glo','esttr_glo'],['tctr_glo','sttr_glo'],['etctr_glo','esttr_glo'],['tctr_glo','sttr_glo']]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcan_nwp'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec_list[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverFlood(Hazard):\n",
    "    \"\"\"Contains flood events\n",
    "    Flood intensities are calculated by means of the\n",
    "    CaMa-Flood global hydrodynamic model\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "        fla_event       (1d array(n_events)) total flooded area for every event\n",
    "        fla_annual      (1d array (n_years)) total flooded area for every year\n",
    "        fla_ann_av      (float) average flooded area per year\n",
    "        fla_ev_av       (float) average flooded area per event\n",
    "        fla_ann_centr   (2d array(n_years x n_centroids)) flooded area in\n",
    "                        every centroid for every event\n",
    "        fla_ev_centr    (2d array(n_events x n_centroids)) flooded area in\n",
    "                        every centroid for every event\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Empty constructor\"\"\"\n",
    "\n",
    "        Hazard.__init__(self, HAZ_TYPE)\n",
    "\n",
    "    def set_from_nc(self, dph_path=None, frc_path=None, origin=False,\n",
    "                    centroids=None, countries=None, reg=None, shape=None, ISINatIDGrid=False,\n",
    "                    years=[2000]):\n",
    "        \"\"\"Wrapper to fill hazard from nc_flood file\n",
    "        Parameters:\n",
    "            dph_path (string): Flood file to read (depth)\n",
    "            frc_path (string): Flood file to read (fraction)\n",
    "            origin (bool): Historical or probabilistic event\n",
    "            centroids (Centroids): centroids to extract\n",
    "            countries (list of countries ISO3) selection of countries\n",
    "                (reg must be None!)\n",
    "            reg (list of regions): can be set with region code if whole areas\n",
    "                are considered (if not None, countries and centroids\n",
    "                are ignored)\n",
    "            ISINatIDGrid (Bool): Indicates whether ISIMIP_NatIDGrid is used\n",
    "            years (int list): years that are considered\n",
    "\n",
    "        raises:\n",
    "            NameError\n",
    "        \"\"\"\n",
    "        if dph_path is None:\n",
    "            LOGGER.error('No flood-depth-path set')\n",
    "            raise NameError\n",
    "        if frc_path is None:\n",
    "            LOGGER.error('No flood-fraction-path set')\n",
    "            raise NameError\n",
    "        if not os.path.exists(dph_path):\n",
    "            LOGGER.error('Invalid flood-file path %s', dph_path)\n",
    "            raise NameError\n",
    "        if not os.path.exists(frc_path):\n",
    "            LOGGER.error('Invalid flood-file path %s', frc_path)\n",
    "            raise NameError\n",
    "\n",
    "        with xr.open_dataset(dph_path) as flood_dph:\n",
    "            time = flood_dph.time.data\n",
    "\n",
    "        event_index = self._select_event(time, years)\n",
    "        bands = event_index + 1\n",
    "\n",
    "        if countries or reg:\n",
    "            # centroids as points\n",
    "            if ISINatIDGrid:\n",
    "\n",
    "                dest_centroids = RiverFlood._select_exact_area(countries, reg)[0]\n",
    "                meta_centroids = copy.copy(dest_centroids)\n",
    "                meta_centroids.set_lat_lon_to_meta()\n",
    "\n",
    "                self.set_raster(files_intensity=[dph_path],\n",
    "                                files_fraction=[frc_path], band=bands.tolist(),\n",
    "                                transform=meta_centroids.meta['transform'],\n",
    "                                width=meta_centroids.meta['width'],\n",
    "                                height=meta_centroids.meta['height'],\n",
    "                                resampling=Resampling.nearest)\n",
    "                x_i = ((dest_centroids.lon - self.centroids.meta['transform'][2]) /\n",
    "                       self.centroids.meta['transform'][0]).astype(int)\n",
    "                y_i = ((dest_centroids.lat - self.centroids.meta['transform'][5]) /\n",
    "                       self.centroids.meta['transform'][4]).astype(int)\n",
    "\n",
    "                fraction = self.fraction[:, y_i * self.centroids.meta['width'] + x_i]\n",
    "                intensity = self.intensity[:, y_i * self.centroids.meta['width'] + x_i]\n",
    "\n",
    "                self.centroids = dest_centroids\n",
    "                self.intensity = sp.sparse.csr_matrix(intensity)\n",
    "                self.fraction = sp.sparse.csr_matrix(fraction)\n",
    "            else:\n",
    "                if reg:\n",
    "                    iso_codes = region2isos(reg)\n",
    "                    # envelope containing counties\n",
    "                    cntry_geom = get_land_geometry(iso_codes)\n",
    "                    self.set_raster(files_intensity=[dph_path],\n",
    "                                    files_fraction=[frc_path],\n",
    "                                    band=bands.tolist(),\n",
    "                                    geometry=cntry_geom)\n",
    "                    # self.centroids.set_meta_to_lat_lon()\n",
    "                else:\n",
    "                    cntry_geom = get_land_geometry(countries)\n",
    "                    self.set_raster(files_intensity=[dph_path],\n",
    "                                    files_fraction=[frc_path],\n",
    "                                    band=bands.tolist(),\n",
    "                                    geometry=cntry_geom)\n",
    "                    # self.centroids.set_meta_to_lat_lon()\n",
    "\n",
    "        elif shape:\n",
    "            shapes = gpd.read_file(shape)\n",
    "\n",
    "            rand_geom = shapes.geometry[0]\n",
    "\n",
    "            self.set_raster(files_intensity=[dph_path],\n",
    "                            files_fraction=[frc_path],\n",
    "                            band=bands.tolist(),\n",
    "                            geometry=rand_geom)\n",
    "            return\n",
    "\n",
    "        elif not centroids:\n",
    "            # centroids as raster\n",
    "            self.set_raster(files_intensity=[dph_path],\n",
    "                            files_fraction=[frc_path],\n",
    "                            band=bands.tolist())\n",
    "            # self.centroids.set_meta_to_lat_lon()\n",
    "\n",
    "        else:  # use given centroids\n",
    "            # if centroids.meta or grid_is_regular(centroids)[0]:\n",
    "            \"\"\"TODO: implement case when meta or regulargrid is defined\n",
    "                     centroids.meta or grid_is_regular(centroidsxarray)[0]:\n",
    "                     centroids>flood --> error\n",
    "                     reprojection, resampling.average (centroids< flood)\n",
    "                     (transform)\n",
    "                     reprojection change resampling\"\"\"\n",
    "            # else:\n",
    "            if centroids.meta:\n",
    "                centroids.set_meta_to_lat_lon()\n",
    "            metafrc, fraction = read_raster(frc_path, band=bands.tolist())\n",
    "            metaint, intensity = read_raster(dph_path, band=bands.tolist())\n",
    "            x_i = ((centroids.lon - metafrc['transform'][2]) /\n",
    "                   metafrc['transform'][0]).astype(int)\n",
    "            y_i = ((centroids.lat - metafrc['transform'][5]) /\n",
    "                   metafrc['transform'][4]).astype(int)\n",
    "            fraction = fraction[:, y_i * metafrc['width'] + x_i]\n",
    "            intensity = intensity[:, y_i * metaint['width'] + x_i]\n",
    "            self.centroids = centroids\n",
    "            self.intensity = sp.sparse.csr_matrix(intensity)\n",
    "            self.fraction = sp.sparse.csr_matrix(fraction)\n",
    "\n",
    "        self.units = 'm'\n",
    "        self.tag.file_name = dph_path + ';' + frc_path\n",
    "        self.event_id = np.arange(self.intensity.shape[0])\n",
    "        self.event_name = list(map(str, years))\n",
    "\n",
    "        if origin:\n",
    "            self.orig = np.ones(self.size, bool)\n",
    "        else:\n",
    "            self.orig = np.zeros(self.size, bool)\n",
    "\n",
    "        self.frequency = np.ones(self.size) / self.size\n",
    "\n",
    "        with xr.open_dataset(dph_path) as flood_dph:\n",
    "            self.date = np.array([dt.datetime(flood_dph.time[i].dt.year,\n",
    "                                              flood_dph.time[i].dt.month,\n",
    "                                              flood_dph.time[i].dt.day).toordinal()\n",
    "                                  for i in event_index])\n",
    "\n",
    "    def _select_event(self, time, years):\n",
    "        \"\"\"\n",
    "        Selects events only in specific years and returns corresponding event\n",
    "        indices\n",
    "        Parameters:\n",
    "            time: event time stemps (array datetime64)\n",
    "            years: years to be selcted (int array)\n",
    "        Raises:\n",
    "            KeyError\n",
    "        Returns:\n",
    "            event indices (int array)\n",
    "        \"\"\"\n",
    "        event_names = pd.to_datetime(time).year\n",
    "        event_index = np.where(np.isin(event_names, years))[0]\n",
    "        if len(event_index) == 0:\n",
    "            LOGGER.error('No events found for selected %s', years)\n",
    "            raise AttributeError\n",
    "        self.event_name = list(map(str, pd.to_datetime(time[event_index])))\n",
    "        return event_index\n",
    "\n",
    "    def exclude_trends(self, fld_trend_path, dis):\n",
    "        \"\"\"\n",
    "        Function allows to exclude flood impacts that are caused in areas\n",
    "        exposed discharge trends other than the selected one. (This function\n",
    "        is only needed for very specific applications)\n",
    "        Raises:\n",
    "            NameError\n",
    "        \"\"\"\n",
    "        if not os.path.exists(fld_trend_path):\n",
    "            LOGGER.error('Invalid ReturnLevel-file path %s', fld_trend_path)\n",
    "            raise NameError\n",
    "        else:\n",
    "            metafrc, trend_data = read_raster(fld_trend_path, band=[1])\n",
    "            x_i = ((self.centroids.lon - metafrc['transform'][2]) /\n",
    "                   metafrc['transform'][0]).astype(int)\n",
    "            y_i = ((self.centroids.lat - metafrc['transform'][5]) /\n",
    "                   metafrc['transform'][4]).astype(int)\n",
    "\n",
    "        trend = trend_data[:, y_i * metafrc['width'] + x_i]\n",
    "\n",
    "        if dis == 'pos':\n",
    "            dis_map = np.greater(trend, 0)\n",
    "        else:\n",
    "            dis_map = np.less(trend, 0)\n",
    "\n",
    "        new_trends = dis_map.astype(int)\n",
    "\n",
    "        new_intensity = np.multiply(self.intensity.todense(), new_trends)\n",
    "        new_fraction = np.multiply(self.fraction.todense(), new_trends)\n",
    "\n",
    "        self.intensity = sp.sparse.csr_matrix(new_intensity)\n",
    "        self.fraction = sp.sparse.csr_matrix(new_fraction)\n",
    "\n",
    "    def exclude_returnlevel(self, frc_path):\n",
    "        \"\"\"\n",
    "        Function allows to exclude flood impacts below a certain return level\n",
    "        by manipulating flood fractions in a way that the array flooded more\n",
    "        frequently than the treshold value is excluded. (This function\n",
    "        is only needed for very specific applications)\n",
    "        Raises:\n",
    "            NameErroris function\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists(frc_path):\n",
    "            LOGGER.error('Invalid ReturnLevel-file path %s', frc_path)\n",
    "            raise NameError\n",
    "        else:\n",
    "            metafrc, fraction = read_raster(frc_path, band=[1])\n",
    "            x_i = ((self.centroids.lon - metafrc['transform'][2]) /\n",
    "                   metafrc['transform'][0]).astype(int)\n",
    "            y_i = ((self.centroids.lat - metafrc['transform'][5]) /\n",
    "                   metafrc['transform'][4]).astype(int)\n",
    "            fraction = fraction[:, y_i * metafrc['width'] + x_i]\n",
    "            new_fraction = np.array(np.subtract(self.fraction.todense(),\n",
    "                                                fraction))\n",
    "            new_fraction = new_fraction.clip(0)\n",
    "            self.fraction = sp.sparse.csr_matrix(new_fraction)\n",
    "\n",
    "    def set_flooded_area(self, save_centr=False):\n",
    "        \"\"\"\n",
    "        Calculates flooded area for hazard. sets yearly flooded area and\n",
    "            flooded area per event\n",
    "        Raises:\n",
    "            MemoryError\n",
    "        \"\"\"\n",
    "        self.centroids.set_area_pixel()\n",
    "        area_centr = self.centroids.area_pixel\n",
    "        event_years = np.array([date.fromordinal(self.date[i]).year\n",
    "                                for i in range(len(self.date))])\n",
    "        years = np.unique(event_years)\n",
    "        year_ev_mk = self._annual_event_mask(event_years, years)\n",
    "\n",
    "        fla_ann_centr = np.zeros((len(years), len(self.centroids.lon)))\n",
    "        fla_ev_centr = np.array(np.multiply(self.fraction.todense(),\n",
    "                                            area_centr))\n",
    "        self.fla_event = np.sum(fla_ev_centr, axis=1)\n",
    "        for year_ind in range(len(years)):\n",
    "            fla_ann_centr[year_ind, :] =\\\n",
    "                np.sum(fla_ev_centr[year_ev_mk[year_ind, :], :],\n",
    "                       axis=0)\n",
    "        self.fla_annual = np.sum(fla_ann_centr, axis=1)\n",
    "        self.fla_ann_av = np.mean(self.fla_annual)\n",
    "        self.fla_ev_av = np.mean(self.fla_event)\n",
    "        if save_centr:\n",
    "            self.fla_ann_centr = sp.sparse.csr_matrix(fla_ann_centr)\n",
    "            self.fla_ev_centr = sp.sparse.csr_matrix(fla_ev_centr)\n",
    "\n",
    "    def _annual_event_mask(self, event_years, years):\n",
    "        \"\"\"Assignes events to each year\n",
    "        Returns:\n",
    "            bool array (columns contain events, rows contain years)\n",
    "        \"\"\"\n",
    "        event_mask = np.full((len(years), len(event_years)), False, dtype=bool)\n",
    "        for year_ind in range(len(years)):\n",
    "            events = np.where(event_years == years[year_ind])[0]\n",
    "            event_mask[year_ind, events] = True\n",
    "        return event_mask\n",
    "\n",
    "    def set_flood_volume(self, save_centr=False):\n",
    "        \"\"\"Calculates flooded area for hazard. sets yearly flooded area and\n",
    "            flooded area per event\n",
    "        Raises:\n",
    "            MemoryError\n",
    "        \"\"\"\n",
    "\n",
    "        fv_ann_centr = np.multiply(self.fla_ann_centr.todense(), self.intensity.todense())\n",
    "\n",
    "        if save_centr:\n",
    "            self.fv_ann_centr = sp.sparse.csr_matrix(self.fla_ann_centr)\n",
    "        self.fv_annual = np.sum(fv_ann_centr, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _select_exact_area(countries=[], reg=[]):\n",
    "        \"\"\"Extract coordinates of selected countries or region\n",
    "        from NatID grid. If countries are given countries are cut,\n",
    "        if only reg is given, the whole region is cut.\n",
    "        Parameters:\n",
    "            countries: List of countries\n",
    "            reg: List of regions\n",
    "        Raises:\n",
    "            KeyError\n",
    "        Returns:\n",
    "            centroids\n",
    "        \"\"\"\n",
    "        lat, lon = get_region_gridpoints(countries=countries, regions=reg,\n",
    "                                         basemap=\"isimip\", resolution=150)\n",
    "\n",
    "        if reg:\n",
    "            country_isos = region2isos(reg)\n",
    "        else:\n",
    "            country_isos = countries\n",
    "\n",
    "        natIDs = country_iso2natid(country_isos)\n",
    "\n",
    "        centroids = Centroids()\n",
    "        centroids.set_lat_lon(lat, lon)\n",
    "        centroids.id = np.arange(centroids.lon.shape[0])\n",
    "        # centroids.set_region_id()\n",
    "        return centroids, country_isos, natIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os, csv, sys \n",
    "import scipy\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import random\n",
    "from netCDF4 import Dataset\n",
    "import itertools\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(file_num, file_num_tot, start):\n",
    "    percent_complete = (file_num/file_num_tot)*100\n",
    "    end = time.time()\n",
    "    sys.stdout.write('\\r%.3f %s, %s: %.1f' % (percent_complete, '% Completed', 'time elapsed', end-start))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = # 'your email'\n",
    "pswd = # 'your password'\n",
    "\n",
    "data_obs_folder = '../data/obs/'\n",
    "data_models_folder = '../data/temporarily_downloaded/'\n",
    "results_folder = '../CSVs/multicyclone/'\n",
    "\n",
    "delete_previous_results_files = 'y'\n",
    "save_csv_files = 'y'  # one per model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclone names from observation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.read_csv(data_obs_folder+'best_track_27ty.csv')\n",
    "\n",
    "cyclone_names = [x.lower().strip() for x in sorted(list(set(df_obs['STORMNAME'])))]#+['vongfong']\n",
    "\n",
    "p = {}\n",
    "p['durian'] = ['durian', 'reming']\n",
    "p['fengshen'] = ['fengshen', 'frank']\n",
    "p['ketsana'] = ['ketsana', 'ondoy']\n",
    "p['conson'] = ['conson', 'basyang']\n",
    "p['nesat'] = ['nesat', 'pedring']\n",
    "p['bopha'] = ['bopha', 'pablo']\n",
    "p['utor'] = ['utor', 'labuyo']\n",
    "p['trami'] = ['trami', 'maring']\n",
    "p['usagi'] = ['usagi', 'odette']\n",
    "p['nari'] = ['nari', 'santi']\n",
    "p['krosa'] = ['krosa', 'vinta']\n",
    "p['haiyan'] = ['haiyan', 'yolanda']\n",
    "p['lingling'] = ['lingling', 'agaton']\n",
    "p['rammasun'] = ['rammasun', 'glenda']\n",
    "p['kalmaegi'] = ['kalmaegi', 'luis']\n",
    "p['fung-wong'] = ['fung-wong', 'fungwong', 'fung wong', 'fung_wong', 'mario']\n",
    "p['hagupit'] = ['hagupit', 'ruby']\n",
    "p['mekkhala'] = ['mekkhala', 'amang']\n",
    "p['noul'] = ['noul', 'dodong']\n",
    "p['goni'] = ['goni', 'ineng']\n",
    "p['mujigae'] = ['mujigae', 'kabayan']\n",
    "p['koppu'] = ['koppu', 'lando']\n",
    "p['melor'] = ['melor', 'nona']\n",
    "p['sarika'] = ['sarika', 'karen']\n",
    "p['vongfong'] = ['vongfong', 'ambo']\n",
    "p['haima'] = ['haima', 'lawin']\n",
    "p['nock-ten'] = ['nock-ten', 'nockten', 'nock ten', 'nock_ten', 'nina']\n",
    "p['mangkhut'] = ['mangkhut', 'ompong']\n",
    "\n",
    "cyclone_possible_names = [p[x] for x in cyclone_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import getpass\n",
    "    input = getpass.getpass\n",
    "except:\n",
    "    try:\n",
    "        input = raw_input\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "values = {'email' : email, 'passwd' : pswd, 'action' : 'login'}\n",
    "login_url = 'https://rda.ucar.edu/cgi-bin/login'\n",
    "\n",
    "ret = requests.post(login_url, data=values)\n",
    "if ret.status_code != 200:\n",
    "    print('Bad Authentication')\n",
    "    print('ret.text')\n",
    "    exit(1)\n",
    "    \n",
    "dspath = 'https://rda.ucar.edu/data/ds330.3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create filelist to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institute_list = ['RJTD', 'ecmf', 'egrr', 'kwbc']\n",
    "model_list = [['GSM','GEM','TEM','WFM'],['ifs'],['mogreps'],['CENS','CMC','GEFS','GFS']]\n",
    "model_spec_list = [[['tcan_nwp','tctr_nwp'],['etctr_nwp'],['etctr_nwp'],['etctr_nwp']],[['all_glo']],[['etctr_glo']],[['etctr_glo','esttr_glo'],['tctr_glo','sttr_glo'],['etctr_glo','esttr_glo'],['tctr_glo','sttr_glo']]]\n",
    "\n",
    "year_list = [str(x) if x>9 else '0'+str(x) for x in range(2006, 2021)]\n",
    "year_list.remove('2007')\n",
    "year_list.remove('2017')\n",
    "year_list.remove('2018')\n",
    "\n",
    "month_list = [['11','12'],['06'],['09'],['07'],['09'],['11','12'],['08','09','10','10','11'],['01','02','07','09','11','12'],['01','05','08','09','10','12'],['10'],['12'],['05']]\n",
    "day_list_preliminary = [[[27,30],[1,2]],[[17,27]],[[24,30]],[[11,18]],[[23,30]],[[25,30],[1,9]],[[8,24],[16,24],[8,16],[27,31],[1,11]],[[10,31],[1,2],[9,20],[10,25],[29,30],[1,12]],[[13,21],[2,16],[13,30],[29,30],[1,21],[10,17]],[[13,19]],[[19,29]],[[10,18]]]\n",
    "hour_list = ['00','06','12','18']\n",
    "\n",
    "day_list = []\n",
    "\n",
    "for y in day_list_preliminary:\n",
    "    months = []\n",
    "    for m in y:\n",
    "        days = [str(x) if x>9 else '0'+str(x) for x in range(m[0], m[1]+1)]\n",
    "        months.append(days)\n",
    "    day_list.append(months)\n",
    "    \n",
    "filelist = []\n",
    "\n",
    "for i,institute in enumerate(institute_list):\n",
    "    for mod,model in enumerate(model_list[i]):\n",
    "        for model_spec in model_spec_list[i][mod]:\n",
    "            for y,year in enumerate(year_list):\n",
    "                for m,month in enumerate(month_list[y]):\n",
    "                    for day in day_list[y][m]:\n",
    "                        for hour in hour_list:\n",
    "                            filename = institute.lower()+'/'+year+'/'+year+month+day+'/z_tigge_c_'+institute+'_'+year+month+day+hour+'0000_'+model+'_glob_prod_'+model_spec+'.xml'\n",
    "                            filelist.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "\n",
    "for folder_name in [data_models_folder, results_folder]:\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "        \n",
    "# Initialise lists\n",
    "\n",
    "file_list = []\n",
    "file_list_short = []\n",
    "list_failed1 = []\n",
    "list_total = []\n",
    "institutes = []\n",
    "    \n",
    "\n",
    "# Create list institutes\n",
    "    \n",
    "institutes = [x.lower().strip() for x in institute_list]\n",
    "                 \n",
    "if delete_previous_results_files == 'y':\n",
    "    for cyclone_name in cyclone_names:\n",
    "        try:\n",
    "            os.remove(results_folder+cyclone_name+'_all.csv')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filelist = filelist[6227:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual download and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "filelist_actual = []\n",
    "\n",
    "for file_num, file in enumerate(filelist):\n",
    "    filename = dspath + file\n",
    "    check_status(file_num, len(filelist), start)\n",
    "    outfile = data_models_folder + os.path.basename(filename)      \n",
    "    r = requests.head(filename, cookies = ret.cookies, allow_redirects=False)\n",
    "    if r.status_code == 200:\n",
    "        filelist_actual.append(file)\n",
    "        req = requests.get(filename, cookies = ret.cookies, allow_redirects=False)\n",
    "        open(outfile, 'wb').write(req.content)\n",
    "        CXML_to_csv(outfile, cyclone_names, cyclone_possible_names, results_folder)\n",
    "        os.remove(outfile)\n",
    "    else:\n",
    "        r_gz = requests.head(filename+'.gz', cookies = ret.cookies, allow_redirects=False)\n",
    "        if r_gz.status_code == 200:\n",
    "            filelist_actual.append(file+'.gz')\n",
    "            req_gz = requests.get(filename+'.gz', cookies = ret.cookies, allow_redirects=False)\n",
    "            open(outfile+'.gz', 'wb').write(req_gz.content)\n",
    "            CXML_to_csv(outfile+'.gz', cyclone_names, cyclone_possible_names, results_folder)\n",
    "            os.remove(outfile+'.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

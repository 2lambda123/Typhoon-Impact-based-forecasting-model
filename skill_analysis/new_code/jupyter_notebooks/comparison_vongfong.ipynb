{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, csv, sys \n",
    "import scipy\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import random\n",
    "from netCDF4 import Dataset\n",
    "import itertools\n",
    "import geopy.distance\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandaframe from xml files and save it as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "cyclone_names = ['vongfong']\n",
    "\n",
    "data_folder = '../data/vongfong_all_times/'\n",
    "results_folder = '../CSVs/vongfong/'\n",
    "figures_folder = '../figures/vongfong/'\n",
    "\n",
    "delete_previous_results_files = 'y'\n",
    "save_csv_files = 'y'  # one per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "\n",
    "for folder_name in [data_folder, results_folder, figures_folder]:\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "        \n",
    "# Initialise lists\n",
    "\n",
    "file_list = []\n",
    "file_list_short = []\n",
    "list_failed1 = []\n",
    "list_total = []\n",
    "institutes = []\n",
    "    \n",
    "\n",
    "# Create list with filenames and delete previously created results files\n",
    "    \n",
    "for file in os.listdir(data_folder):\n",
    "    if '.xml' in file:\n",
    "        if '.xml' in file[-4:]:\n",
    "            xml_file_short = file\n",
    "        else:\n",
    "            xml_file_short = file[:-3]  \n",
    "        if xml_file_short not in file_list_short:\n",
    "            file_list.append(data_folder+file)\n",
    "            file_list_short.append(xml_file_short)\n",
    "            institute = file.split('_')[3].lower()\n",
    "            if institute not in institutes:\n",
    "                institutes.append(institute)\n",
    "                 \n",
    "if delete_previous_results_files == 'y':\n",
    "    for cyclone_name in cyclone_names:\n",
    "        try:\n",
    "            os.remove(results_folder+cyclone_name+'_all.csv')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over list of filenames         \n",
    "        \n",
    "for data in file_list:\n",
    "\n",
    "    # Institute name from filename\n",
    "    institute_name = os.path.basename(data).split('_')[3].lower()\n",
    "\n",
    "    # Read file\n",
    "    if data.endswith('.xml'):\n",
    "        try:\n",
    "            tree = ET.parse(data)\n",
    "            root = tree.getroot()\n",
    "        except:\n",
    "            list_failed1.append(data)\n",
    "            pass\n",
    "\n",
    "    elif data.endswith('.gz'):\n",
    "        try:\n",
    "            tree = ET.parse(gzip.open(data))  \n",
    "            root = tree.getroot()\n",
    "        except:\n",
    "            list_failed1.append(data)\n",
    "            pass\n",
    "\n",
    "    # Check how many files could not be parsed\n",
    "    try:\n",
    "        model_name=root.find('header/generatingApplication/model/name').text \n",
    "    except:\n",
    "        model_name='NAN'\n",
    "        pass\n",
    "    print(len(list_failed1))\n",
    "    prod_center=root.find('header/productionCenter').text\n",
    "    baseTime=root.find('header/baseTime').text\n",
    "\n",
    "    ## Create one dictonary for each time point, and append it to a list\n",
    "    \n",
    "    for members in root.findall('data'):\n",
    "        \n",
    "        Mtype=members.get('type')\n",
    "         \n",
    "        for members2 in members.findall('disturbance'):\n",
    "            try: \n",
    "                cyclone_name = [name.text.lower().strip() for name in members2.findall('cycloneName')]\n",
    "            except:\n",
    "                cyclone_name = [' ']\n",
    "                \n",
    "            if cyclone_name and cyclone_name[0] in cyclone_names:\n",
    "                \n",
    "                list_data = []\n",
    "        \n",
    "                if Mtype in ['forecast','ensembleForecast']:\n",
    "                    for members3 in members2.findall('fix'):\n",
    "                        tem_dic={}\n",
    "                        tem_dic['Mtype']=[Mtype]\n",
    "                        tem_dic['institute_name']=[institute_name.lower()]\n",
    "                        tem_dic['product']=[re.sub('\\s+',' ',prod_center).strip().lower()]\n",
    "                        if model_name != 'NAN':\n",
    "                            tem_dic['model_name']=[model_name.lower()]\n",
    "                        else:\n",
    "                            tem_dic['model_name'] = tem_dic['product']\n",
    "                        tem_dic['basin'] = [name.text for name in members2.findall('basin')]\n",
    "                        tem_dic['cycloneName'] = cyclone_name\n",
    "                        tem_dic['cycloneNumber'] = [name.text for name in members2.findall('cycloneNumber')]\n",
    "                        tem_dic['ensemble']=[members.get('member')]#[member]\n",
    "                        tem_dic['cyc_speed'] = [name.text for name in members3.findall('cycloneData/maximumWind/speed')]\n",
    "                        #tem_dic['cyc_speed'] = [name.text for name in members3.findall('cycloneData/minimumPressure/pressure')]\n",
    "                        tem_dic['cyc_cat'] = [name.text for name in members3.findall('cycloneData/development')]\n",
    "                        time = [name.text for name in members3.findall('validTime')]\n",
    "                        tem_dic['time'] = ['/'.join(time[0].split('T')[0].split('-'))+', '+time[0].split('T')[1][:-1]]\n",
    "                        tem_dic['lat'] = [name.text for name in members3.findall('latitude')]\n",
    "                        tem_dic['lon']= [name.text for name in members3.findall('longitude')]                \n",
    "                        tem_dic['vhr']=[members3.get('hour')]\n",
    "    #                     validt=tem_dic['validt'][0].split('-')[0]+tem_dic['validt'][0].split('-')[1]+tem_dic['validt'][0].split('-')[2][:2]+tem_dic['validt'][0].split('-')[2][3:5]\n",
    "    #                     date_object = datetime.strptime(validt, \"%Y%m%d%H\")\n",
    "    #                     s1 = date_object.strftime(\"%m/%d/%Y, %H:00:00\")\n",
    "    #                     tem_dic['time']=[s1]\n",
    "    #                     validt2=members2.get('ID').split('_')[0]\n",
    "    #                     date_object = datetime.strptime(validt2, \"%Y%m%d%H\")\n",
    "    #                     s2 = date_object.strftime(\"%m/%d/%Y, %H:00:00\")\n",
    "    #                     tem_dic['validt2']=[s2] \n",
    "                        tem_dic['forecast_time'] = ['/'.join(baseTime.split('T')[0].split('-'))+', '+baseTime.split('T')[1][:-1]]\n",
    "                        tem_dic1 = dict( [(k,''.join(str(e).lower().strip() for e in v)) for k,v in tem_dic.items()])\n",
    "                        list_data.append(tem_dic1)\n",
    "                        list_total.append(tem_dic1)\n",
    "                    \n",
    "                elif Mtype=='analysis':\n",
    "\n",
    "                    tem_dic={}\n",
    "                    tem_dic['Mtype']=['analysis']\n",
    "                    tem_dic['institute_name']=[institute_name.lower()]\n",
    "                    tem_dic['product']=[re.sub('\\s+',' ',prod_center).strip().lower()]\n",
    "                    if model_name != 'NAN':\n",
    "                        tem_dic['model_name']=[model_name.lower()]\n",
    "                    else:\n",
    "                        tem_dic['model_name'] = tem_dic['product']\n",
    "                    tem_dic['basin']= [name.text for name in members2.findall('basin')]\n",
    "                    tem_dic['cycloneName'] = cyclone_name\n",
    "                    tem_dic['cycloneNumber'] = [name.text for name in members2.findall('cycloneNumber')]\n",
    "                    tem_dic['ensemble']=['NAN']\n",
    "                    tem_dic['cyc_speed'] = [name.text for name in members2.findall('cycloneData/maximumWind/speed')]\n",
    "                    #tem_dic['cyc_speed'] = [name.text for name in members2.findall('cycloneData/minimumPressure/pressure')]\n",
    "                    tem_dic['cyc_cat'] = [name.text for name in members2.findall('cycloneData/development')]\n",
    "                    time = [name.text for name in members2.findall('fix/validTime')]\n",
    "                    tem_dic['time'] = ['/'.join(time[0].split('T')[0].split('-'))+', '+time[0].split('T')[1][:-1]]\n",
    "                    tem_dic['lat'] = [name.text for name in members2.findall('fix/latitude')]\n",
    "                    tem_dic['lon']= [name.text for name in members2.findall('fix/longitude')]\n",
    "                    tem_dic['vhr']=[members2.get('hour')]\n",
    "    #                 validt=tem_dic['validt'][0].split('-')[0]+tem_dic['validt'][0].split('-')[1]+tem_dic['validt'][0].split('-')[2][:2]+tem_dic['validt'][0].split('-')[2][3:5]\n",
    "    #                 date_object = datetime.strptime(validt, \"%Y%m%d%H\")\n",
    "    #                 s1 = date_object.strftime(\"%m/%d/%Y, %H:00:00\")\n",
    "    #                 tem_dic['validt']=[s1]\n",
    "    #                 validt2=members2.get('ID').split('_')[0]\n",
    "    #                 date_object = datetime.strptime(validt2, \"%Y%m%d%H\")\n",
    "    #                 s2 = date_object.strftime(\"%m/%d/%Y, %H:00:00\")\n",
    "    #                 tem_dic['validt2']=[s2]\n",
    "                    tem_dic['forecast_time'] = ['/'.join(baseTime.split('T')[0].split('-'))+', '+baseTime.split('T')[1][:-1]]\n",
    "                    tem_dic1 = dict( [(k,''.join(str(e).lower().strip() for e in v)) for k,v in tem_dic.items()])\n",
    "                    list_data.append(tem_dic1)\n",
    "                    list_total.append(tem_dic1)\n",
    "\n",
    "                # Save the databases to the csv files (one for each institute)\n",
    "                if save_csv_files == 'y':\n",
    "\n",
    "                    # Define csv file\n",
    "                    csv_file = results_folder+cyclone_name[0]+'_all.csv'\n",
    "\n",
    "                    # Headers\n",
    "                    csv_columns = tem_dic1.keys()\n",
    "\n",
    "                    if os.path.exists(csv_file):\n",
    "                        append_write = 'a' # append if already exists\n",
    "                    else:\n",
    "                        append_write = 'w' # make a new file if not\n",
    "\n",
    "                    # Write data\n",
    "                    try:\n",
    "                        with open(csv_file, append_write) as csvfile:\n",
    "                            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "                            if append_write == 'w':\n",
    "                                writer.writeheader()\n",
    "                            for row in list_data:\n",
    "                                writer.writerow(row)\n",
    "                    except IOError:\n",
    "                        print(\"I/O error\")\n",
    "            \n",
    "            \n",
    "## Create pandas dataframe\n",
    "df_store=pd.DataFrame(list_total)\n",
    "df_store = df_store[['Mtype', 'institute_name', 'product', 'model_name', 'basin', 'cycloneName', 'cycloneNumber', 'ensemble', 'cyc_speed', 'cyc_cat', 'time', 'lat', 'lon', 'vhr', 'forecast_time']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_3]",
   "language": "python",
   "name": "conda-env-python_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, csv, sys \n",
    "import scipy\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import random\n",
    "from netCDF4 import Dataset\n",
    "import itertools\n",
    "import geopy.distance\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandaframe from xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "data_obs_folder = '../data/obs/'\n",
    "UCL_folder = '../data/UCL_all/'\n",
    "results_folder = '../CSVs/multicyclone/'\n",
    "figures_folder = '../figures/multicyclone/'\n",
    "\n",
    "include_UCL_data = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.read_csv(data_obs_folder+'best_track_27ty.csv')\n",
    "\n",
    "cyclone_names_upper = [x for x in sorted(list(set(df_obs['STORMNAME'])))]+['vongfong']\n",
    "\n",
    "cyclone_names_upper.remove('KETSANA')\n",
    "cyclone_names_upper.remove('FENGSHEN')\n",
    "cyclone_names_upper.remove('DURIAN')\n",
    "cyclone_names_upper.remove('NOCK-TEN')\n",
    "\n",
    "cyclone_names = [x.lower().strip() for x in cyclone_names_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {}\n",
    "\n",
    "for c, cyclone_name in enumerate(cyclone_names):\n",
    "    cyclone_name_upper = cyclone_names_upper[c]\n",
    "    obs[cyclone_name] = {}\n",
    "    if cyclone_name == 'vongfong':\n",
    "        obs[cyclone_name]['track'] = np.array([[9.6,128.8],[10.1,128.8],[10.8,129],[11.4,128.8],[11.9,129.2],[11.8,128.9],[12,128.5],[12.2,127.9],[12.1,127],[12.1,126.2],[12.2,125.3],[12.3,124.9],[12.5,123.6],[13.3,122.7],[14.1,121.9],[15.1,121.4],[16.2,121.1],[18,120],[19.3,120.5]])\n",
    "        time_string = ['1118', '1200', '1206', '1212', '1218', '1300', '1306', '1312', '1318', '1400', '1406', '1412', '1418', '1500', '1506', '1512', '1518', '1600', '1606'] \n",
    "        obs[cyclone_name]['date_time'] = ['2020/05/'+t[:2]+', '+t[2:]+':00:00' for t in time_string]\n",
    "    else:\n",
    "        obs[cyclone_name]['track'] = np.transpose(np.vstack((np.array(df_obs[df_obs['STORMNAME']==cyclone_name_upper]['LAT']),np.array(df_obs[df_obs['STORMNAME']==cyclone_name_upper]['LON']))))\n",
    "        date_time = [str(x) for x in list(df_obs[df_obs['STORMNAME']==cyclone_name_upper]['YYYYMMDDHH'])]\n",
    "        obs[cyclone_name]['date_time'] = [dt[:4]+'/'+dt[4:6]+'/'+dt[6:8]+', '+dt[8:10]+':'+dt[10:12]+':00' for dt in date_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_separation = 6\n",
    "time_limit_list = list(np.linspace(6,72,72/time_separation, dtype=int))\n",
    "# time_limit_list = [72]\n",
    "\n",
    "institutes_selections = [['kwbc'], ['rjtd'], ['egrr'], ['ecmf'], ['kwbc', 'rjtd', 'egrr', 'ecmf'], ['kwbc', 'egrr', 'ecmf'], ['kwbc', 'rjtd', 'ecmf'], ['kwbc', 'ecmf']]\n",
    "selections_names = ['kwbc', 'rjtd', 'egrr', 'ecmf', 'full', 'w_rjtd', 'w_egrr', 'w_rjtd_egrr']\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If the file exists You can jump to load dictionary results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure the results as a dictionary (for each time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary out of the results, with the following sctructure:\n",
    "\n",
    "- number identifying institute and model:\n",
    "    - institute-model name\n",
    "    - cyclone name\n",
    "        - number identifying the forecast time\n",
    "            - forecast time (date and time at which the forecast was started)\n",
    "            - ensemble\n",
    "                - start\n",
    "                - lat\n",
    "                - lon\n",
    "            - ensemble_mean\n",
    "                - start\n",
    "                - lat\n",
    "                - lon\n",
    "            - number_members_ensemble\n",
    "        - number forecast times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over time_limit_list\n",
    "for time_limit in time_limit_list:\n",
    "\n",
    "    print('Time limit: '+str(time_limit))\n",
    "\n",
    "    # Initialise the dictonary\n",
    "    results_t = {}\n",
    "\n",
    "    # Create a list with time points\n",
    "    nhours_list = list(np.linspace(0,time_limit,time_limit/time_separation+1, dtype=int))\n",
    "\n",
    "    # Loop over cyclone names\n",
    "    for cyclone_name in cyclone_names:\n",
    "\n",
    "        # Initialise subdictionary\n",
    "        results_t[cyclone_name] = {}\n",
    "\n",
    "        # Restrict the dataframe to the specific cyclone\n",
    "        df_cyclone = pd.read_csv(results_folder+cyclone_name+'_all.csv')\n",
    "        \n",
    "        # Retrieve model names from the dataframe (the function set removes duplicates from a list)\n",
    "        institute_names = list(set(df_cyclone['institute_name']))\n",
    "\n",
    "        # Initialise model_num (so that the first number will actually be 0)\n",
    "        model_num = -1\n",
    "\n",
    "        # Loop over institutes\n",
    "        for institute_name in institute_names:\n",
    "\n",
    "            # Restrict the dataframe to the specific institute\n",
    "            df_institute = df_cyclone[df_cyclone['institute_name'] == institute_name]\n",
    "\n",
    "            # Retrieve model names from the dataframe (the function set removes duplicates from a list)\n",
    "            model_names = list(set(df_institute['model_name']))\n",
    "\n",
    "            # Loop over models\n",
    "            for model_name in model_names:\n",
    "\n",
    "                model_num += 1\n",
    "\n",
    "                # Initialise subdictionary and assign name\n",
    "                results_t[cyclone_name][str(model_num)] = {}\n",
    "                results_t[cyclone_name][str(model_num)]['model_name'] = institute_name.upper()+' - '+model_name\n",
    "\n",
    "    #             print(model_num, results_t[cyclone_name][str(model_num)]['model_name'])\n",
    "\n",
    "                # Restrict the dataframe to the specific model\n",
    "                df_model = df_institute[df_institute['model_name'] == model_name]\n",
    "\n",
    "                # Restrict the dataframe to the ensemble forecasts\n",
    "                df_ensemble = df_model[df_model['Mtype'] == 'ensembleforecast']\n",
    "\n",
    "                # For each model, each cyclone, retrieve the list of forecast times\n",
    "                forecast_time_list = sorted(list(set(df_ensemble['forecast_time'])))\n",
    "                results_t[cyclone_name][str(model_num)]['num_forecast_times'] = len(forecast_time_list)\n",
    "\n",
    "                # Loop over forecast times\n",
    "                for forecast_time_num, forecast_time in enumerate(forecast_time_list):\n",
    "\n",
    "                    # Initialise lists for lat and lon of paths\n",
    "                    lat_ensemble_list = []\n",
    "                    lon_ensemble_list = []\n",
    "                    date_ensemble_list = []\n",
    "\n",
    "                    # Initialise subdictionary\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)] = {}\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['forecast_time'] = forecast_time\n",
    "\n",
    "                    # Restrict the dataframe to the specific forecast time\n",
    "                    df_time = df_ensemble[df_ensemble['forecast_time'] == forecast_time]\n",
    "\n",
    "                    # Initialise subdictionary ensembles\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble'] = {}\n",
    "\n",
    "                    # For each model, each cyclone, each forecast time, retrieve the list of ensembles\n",
    "                    ensemble_list = sorted([int(x) for x in list(set(df_time['ensemble']))])\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['num_members_ensemble'] = len(ensemble_list)\n",
    "\n",
    "                    # Loop over the member of the ensemble\n",
    "                    for member in ensemble_list:\n",
    "\n",
    "                        # Restrict the dataframe to the ensemble\n",
    "                        df_member = df_time[df_time['ensemble'] == str(member)]\n",
    "\n",
    "                        # Initialise lists for lat and lon of paths\n",
    "                        lat_member = []\n",
    "                        lon_member = []\n",
    "                        date_member = []\n",
    "                        date_int_member = []\n",
    "\n",
    "                        # Loop over the time points\n",
    "                        for nhours in nhours_list:\n",
    "                            # Assign lat and lon\n",
    "                            try:\n",
    "                                lat_member.append(float(df_member[df_member['vhr']==str(nhours)]['lat']))\n",
    "                                lon_member.append(float(df_member[df_member['vhr']==str(nhours)]['lon']))\n",
    "                                date_member.append(list(df_member[df_member['vhr']==str(nhours)]['time'])[0])\n",
    "                            except:\n",
    "                                lat_member.append(np.nan)\n",
    "                                lon_member.append(np.nan)\n",
    "                                date_member.append('')\n",
    "\n",
    "                        lat_ensemble_list.append(lat_member)\n",
    "                        lon_ensemble_list.append(lon_member)\n",
    "                        date_ensemble_list.append(date_member)\n",
    "\n",
    "                    # Store lats and lons in the dictonary (as arrays)\n",
    "                    try:\n",
    "                        results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['start'] = list(df_member[df_member['vhr']==str(0)]['time'])[0]\n",
    "                    except:\n",
    "                        results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['start'] = ''\n",
    "\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lat'] = np.array(lat_ensemble_list)\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lon'] = np.array(lon_ensemble_list)\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['date'] = date_ensemble_list\n",
    "\n",
    "        results_t[cyclone_name]['number_models'] = model_num+1\n",
    "\n",
    "    ## Crete average path over each ensemble\n",
    "\n",
    "    for cyclone_name in cyclone_names:\n",
    "        for model_num in range(results_t[cyclone_name]['number_models']):\n",
    "                for forecast_time_num in range(results_t[cyclone_name][str(model_num)]['num_forecast_times']):\n",
    "                    lat_ens = np.array(results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lat'], dtype=np.float)\n",
    "                    lon_ens = np.array(results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lon'], dtype=np.float)\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean'] = {}\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['start'] = results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['start']\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lat'] = np.nanmean(lat_ens,0)\n",
    "                    results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lon'] = np.nanmean(lon_ens,0)\n",
    "                    try:\n",
    "                        results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['date'] = [sum_date_time(results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['start'], hours=nhours) for nhours in nhours_list]\n",
    "                    except:\n",
    "                        results_t[cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['date'] = ''\n",
    "                        \n",
    "                        \n",
    "    results[str(time_limit)] = results_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_limit in time_limit_list:\n",
    "    \n",
    "    print('Time limit: '+str(time_limit))\n",
    "    \n",
    "    ##### UCL data    \n",
    "    \n",
    "    if include_UCL_data == 'y':\n",
    "        \n",
    "        for cyclone_name in cyclone_names:\n",
    "        \n",
    "            results[str(time_limit)][cyclone_name]['UCL'] = {}\n",
    "\n",
    "            UCL_cyclone_folder = UCL_folder+cyclone_name+'/'\n",
    "\n",
    "            n_file = -1\n",
    "\n",
    "            for UCL_filename in os.listdir(UCL_cyclone_folder):\n",
    "\n",
    "                if 'forecasttrack' in UCL_filename and '.shp' in UCL_filename:\n",
    "\n",
    "                    n_file += 1\n",
    "\n",
    "                    shapefile = gpd.read_file(UCL_cyclone_folder+UCL_filename)\n",
    "\n",
    "                    date_time_UCL = UCL_filename.split('_')[-1][:-4]\n",
    "\n",
    "                    year_UCL = date_time_UCL[0:4]\n",
    "                    month_UCL = date_time_UCL[4:6]\n",
    "                    day_UCL = date_time_UCL[6:8]\n",
    "                    hour_UCL = date_time_UCL[8:10]\n",
    "\n",
    "                    month_UCL = str(int(month_UCL)+1) if int(month_UCL)+1>9 else '0'+str(int(month_UCL)+1)\n",
    "\n",
    "                    forecast_time = year_UCL+'/'+month_UCL+'/'+day_UCL+', '+hour_UCL+':00:00'\n",
    "\n",
    "                    lead_times = np.array([0,  12,  24,  36,  48,  72,  96, 120])\n",
    "\n",
    "                    try:\n",
    "                        if lead_times[-1] > time_limit:\n",
    "                            ind_lead_times_max = np.where(lead_times==time_limit)[0][0]\n",
    "                            lead_times = lead_times[:ind_lead_times_max+1]\n",
    "                        else:\n",
    "                            ind_lead_times_max = len(lead_times)\n",
    "\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)] = {}  \n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['forecast_time'] = forecast_time\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['lat'] = np.array(shapefile.geometry.y)[:ind_lead_times_max+1]\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['lon'] = np.array(shapefile.geometry.x)[:ind_lead_times_max+1]\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['date'] = [sum_date_time(forecast_time, hours=nhours) for nhours in lead_times]\n",
    "\n",
    "                    except:\n",
    "\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)] = {}\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['forecast_time'] = forecast_time\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['lat'] = np.nan\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['lon'] = np.nan\n",
    "                        results[str(time_limit)][cyclone_name]['UCL'][str(n_file)]['date'] = ''\n",
    "\n",
    "            results[str(time_limit)][cyclone_name]['UCL']['num_forecast_times'] = n_file+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate multimodel means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_limit in time_limit_list:\n",
    "    \n",
    "    print('Time limit: '+str(time_limit))\n",
    "\n",
    "    ## List of all forecast times (where each one appears only once)\n",
    "\n",
    "    for cyclone_name in cyclone_names:\n",
    "        forecast_time_list = [] \n",
    "        for model_num in range(results[str(time_limit)][cyclone_name]['number_models']):\n",
    "                for forecast_time_num in range(results[str(time_limit)][cyclone_name][str(model_num)]['num_forecast_times']):\n",
    "                    forecast_time_list.append(results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['forecast_time'])\n",
    "\n",
    "        results[str(time_limit)][cyclone_name]['forecast_time_list'] = sorted(list(set(forecast_time_list)))\n",
    "\n",
    "\n",
    "    ## Create means for each selection of ensemble of models\n",
    "\n",
    "    for cyclone_name in cyclone_names:\n",
    "        results[str(time_limit)][cyclone_name]['multimodel'] = {}\n",
    "        for s,selection in enumerate(institutes_selections):\n",
    "            results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]] = {}\n",
    "            for forecast_time_num_general,forecast_time in enumerate(results[str(time_limit)][cyclone_name]['forecast_time_list']):\n",
    "                n = 0\n",
    "                lats = np.nan\n",
    "                lons = np.nan\n",
    "                for model_num in range(results[str(time_limit)][cyclone_name]['number_models']):\n",
    "                    if results[str(time_limit)][cyclone_name][str(model_num)]['model_name'].split('-')[0].strip().lower() in selection:\n",
    "                        for forecast_time_num in range(results[str(time_limit)][cyclone_name][str(model_num)]['num_forecast_times']):\n",
    "                            if results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['forecast_time'] == forecast_time:\n",
    "                                lat_ens = np.array(results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lat'], dtype=np.float)\n",
    "                                lon_ens = np.array(results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble']['lon'], dtype=np.float)\n",
    "                                if n == 0:\n",
    "                                    lats = lat_ens\n",
    "                                    lons = lon_ens\n",
    "                                else:\n",
    "                                    lats = np.concatenate((lats,lat_ens),axis=0)\n",
    "                                    lons = np.concatenate((lons,lon_ens),axis=0)\n",
    "                                n += 1\n",
    "                results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)] = {}\n",
    "                results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['forecast_time'] = forecast_time\n",
    "                results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['date'] = [sum_date_time(forecast_time, hours=nhours) for nhours in nhours_list]\n",
    "                results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lat'] = np.nanmean(lats,0)\n",
    "                results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lon'] = np.nanmean(lons,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate errors respect to observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_limit in time_limit_list:\n",
    "    \n",
    "    print('Time limit: '+str(time_limit))\n",
    "\n",
    "    # For each model\n",
    "\n",
    "    for cyclone_name in cyclone_names:\n",
    "#         print('Cyclone: '+cyclone_name+'\\n')\n",
    "        for model_num in range(results[str(time_limit)][cyclone_name]['number_models']):\n",
    "\n",
    "            distance_initial_list = []\n",
    "            distance_final_list = []\n",
    "\n",
    "            for forecast_time_num in range(results[str(time_limit)][cyclone_name][str(model_num)]['num_forecast_times']):\n",
    "\n",
    "                date_forecast = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['forecast_time']\n",
    "                dates_list = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['date']\n",
    "\n",
    "                for date_obs in obs[cyclone_name]['date_time']:\n",
    "\n",
    "                    if date_obs in dates_list:\n",
    "\n",
    "                        ind_final = dates_list.index(date_obs)\n",
    "\n",
    "                        try:\n",
    "                            lat_final = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lat'][ind_final]\n",
    "                            lon_final = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lon'][ind_final]\n",
    "                        except:\n",
    "                            lat_final = np.nan\n",
    "                            lon_final = np.nan\n",
    "\n",
    "                        ind_final_obs = obs[cyclone_name]['date_time'].index(date_obs)\n",
    "                        lat_final_obs = obs[cyclone_name]['track'][ind_final_obs,0]\n",
    "                        lon_final_obs = obs[cyclone_name]['track'][ind_final_obs,1]\n",
    "\n",
    "                        date_initial = sum_date_time(date_obs, hours=-time_limit)\n",
    "\n",
    "                        if date_forecast == date_initial:\n",
    "\n",
    "                            ind_initial = dates_list.index(date_forecast)\n",
    "\n",
    "                            try:\n",
    "                                lat_initial = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lat'][ind_initial]\n",
    "                                lon_initial = results[str(time_limit)][cyclone_name][str(model_num)][str(forecast_time_num)]['ensemble_mean']['lon'][ind_initial]\n",
    "                            except:\n",
    "                                lat_initial = np.nan\n",
    "                                lon_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                ind_initial_obs = obs[cyclone_name]['date_time'].index(date_forecast)\n",
    "                                lat_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,0]\n",
    "                                lon_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,1]\n",
    "                            except:\n",
    "                                ind_initial_obs = np.nan\n",
    "                                lat_initial_obs = np.nan\n",
    "                                lon_initial_obs = np.nan\n",
    "\n",
    "                            # Coordinates and distance\n",
    "\n",
    "                            coords_final_theor = (lat_final_obs, lon_final_obs)\n",
    "                            coords_final_model = (lat_final, lon_final)\n",
    "\n",
    "                            coords_initial_theor = (lat_initial_obs, lon_initial_obs)\n",
    "                            coords_initial_model = (lat_initial, lon_initial)\n",
    "\n",
    "                            try:\n",
    "                                distance_initial = geopy.distance.distance(coords_initial_theor, coords_initial_model).km\n",
    "                            except:\n",
    "                                distance_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                distance_final = geopy.distance.distance(coords_final_theor, coords_final_model).km\n",
    "                            except:\n",
    "                                distance_final = np.nan\n",
    "\n",
    "                            distance_initial_list.append(distance_initial)\n",
    "                            distance_final_list.append(distance_final)\n",
    "\n",
    "#                             print(results[str(time_limit)][cyclone_name][str(model_num)]['model_name'], date_forecast, '\\t', distance_initial, distance_final)\n",
    "\n",
    "            results[str(time_limit)][cyclone_name][str(model_num)]['distance_initial'] = np.nanmean(distance_initial_list)\n",
    "            results[str(time_limit)][cyclone_name][str(model_num)]['distance_final'] = np.nanmean(distance_final_list)\n",
    "\n",
    "\n",
    "    # For each multimodel ensemble\n",
    "#         print('\\n')\n",
    "\n",
    "        for s in range(len(selections_names)):\n",
    "\n",
    "            distance_initial_list = []\n",
    "            distance_final_list = []\n",
    "\n",
    "            for forecast_time_num_general in range(len(results[str(time_limit)][cyclone_name]['forecast_time_list'])):\n",
    "\n",
    "                date_forecast = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['forecast_time']\n",
    "                dates_list = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['date']\n",
    "\n",
    "                for date_obs in obs[cyclone_name]['date_time']:\n",
    "\n",
    "                    if date_obs in dates_list:\n",
    "\n",
    "                        ind_final = dates_list.index(date_obs)\n",
    "\n",
    "                        try:\n",
    "                            lat_final = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lat'][ind_final]\n",
    "                            lon_final = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lon'][ind_final]\n",
    "                        except:\n",
    "                            lat_final = np.nan\n",
    "                            lon_final = np.nan\n",
    "\n",
    "                        ind_final_obs = obs[cyclone_name]['date_time'].index(date_obs)\n",
    "                        lat_final_obs = obs[cyclone_name]['track'][ind_final_obs,0]\n",
    "                        lon_final_obs = obs[cyclone_name]['track'][ind_final_obs,1]\n",
    "\n",
    "                        date_initial = sum_date_time(date_obs, hours=-time_limit)\n",
    "\n",
    "                        if date_forecast == date_initial:\n",
    "\n",
    "                            ind_initial = dates_list.index(date_forecast)\n",
    "\n",
    "                            try:\n",
    "                                lat_initial = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lat'][ind_initial]\n",
    "                                lon_initial = results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]][str(forecast_time_num_general)]['lon'][ind_initial]\n",
    "                            except:\n",
    "                                lat_initial = np.nan\n",
    "                                lon_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                ind_initial_obs = obs[cyclone_name]['date_time'].index(date_forecast)\n",
    "                                lat_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,0]\n",
    "                                lon_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,1]\n",
    "                            except:\n",
    "                                ind_initial_obs = np.nan\n",
    "                                lat_initial_obs = np.nan\n",
    "                                lon_initial_obs = np.nan\n",
    "\n",
    "                            # Coordinates and distance\n",
    "\n",
    "                            coords_final_theor = (lat_final_obs, lon_final_obs)\n",
    "                            coords_final_model = (lat_final, lon_final)\n",
    "\n",
    "                            coords_initial_theor = (lat_initial_obs, lon_initial_obs)\n",
    "                            coords_initial_model = (lat_initial, lon_initial)\n",
    "\n",
    "                            try:\n",
    "                                distance_initial = geopy.distance.distance(coords_initial_theor, coords_initial_model).km\n",
    "                            except:\n",
    "                                distance_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                distance_final = geopy.distance.distance(coords_final_theor, coords_final_model).km\n",
    "                            except:\n",
    "                                distance_final = np.nan\n",
    "\n",
    "                            distance_initial_list.append(distance_initial)\n",
    "                            distance_final_list.append(distance_final)\n",
    "\n",
    "#                             print(selections_names[s], date_forecast, '\\t', distance_initial, distance_final)\n",
    "\n",
    "            results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]]['distance_initial'] = np.nanmean(distance_initial_list)\n",
    "            results[str(time_limit)][cyclone_name]['multimodel'][selections_names[s]]['distance_final'] = np.nanmean(distance_final_list)\n",
    "\n",
    "\n",
    "    # For UCL\n",
    "        if include_UCL_data == 'y':\n",
    "#         print('\\n')\n",
    "\n",
    "            distance_initial_list = []\n",
    "            distance_final_list = []\n",
    "\n",
    "            for forecast_time_num_general in range(results[str(time_limit)][cyclone_name]['UCL']['num_forecast_times']):\n",
    "\n",
    "                date_forecast = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['forecast_time']\n",
    "                dates_list = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['date']\n",
    "\n",
    "                for date_obs in obs[cyclone_name]['date_time']:\n",
    "\n",
    "                    if date_obs in dates_list:\n",
    "\n",
    "                        ind_final = dates_list.index(date_obs)\n",
    "\n",
    "                        try:\n",
    "                            lat_final = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['lat'][ind_final]\n",
    "                            lon_final = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['lon'][ind_final]\n",
    "                        except:\n",
    "                            lat_final = np.nan\n",
    "                            lon_final = np.nan\n",
    "\n",
    "                        ind_final_obs = obs[cyclone_name]['date_time'].index(date_obs)\n",
    "                        lat_final_obs = obs[cyclone_name]['track'][ind_final_obs,0]\n",
    "                        lon_final_obs = obs[cyclone_name]['track'][ind_final_obs,1]\n",
    "\n",
    "                        date_initial = sum_date_time(date_obs, hours=-time_limit)\n",
    "\n",
    "                        if date_forecast == date_initial:\n",
    "\n",
    "                            ind_initial = dates_list.index(date_forecast)\n",
    "\n",
    "                            try:\n",
    "                                lat_initial = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['lat'][ind_initial]\n",
    "                                lon_initial = results[str(time_limit)][cyclone_name]['UCL'][str(forecast_time_num_general)]['lon'][ind_initial]\n",
    "                            except:\n",
    "                                lat_initial = np.nan\n",
    "                                lon_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                ind_initial_obs = obs[cyclone_name]['date_time'].index(date_forecast)\n",
    "                                lat_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,0]\n",
    "                                lon_initial_obs = obs[cyclone_name]['track'][ind_initial_obs,1]\n",
    "                            except:\n",
    "                                ind_initial_obs = np.nan\n",
    "                                lat_initial_obs = np.nan\n",
    "                                lon_initial_obs = np.nan\n",
    "\n",
    "                            # Coordinates and distance\n",
    "\n",
    "                            coords_final_theor = (lat_final_obs, lon_final_obs)\n",
    "                            coords_final_model = (lat_final, lon_final)\n",
    "\n",
    "                            coords_initial_theor = (lat_initial_obs, lon_initial_obs)\n",
    "                            coords_initial_model = (lat_initial, lon_initial)\n",
    "\n",
    "                            try:\n",
    "                                distance_initial = geopy.distance.distance(coords_initial_theor, coords_initial_model).km\n",
    "                            except:\n",
    "                                distance_initial = np.nan\n",
    "\n",
    "                            try:\n",
    "                                distance_final = geopy.distance.distance(coords_final_theor, coords_final_model).km\n",
    "                            except:\n",
    "                                distance_final = np.nan\n",
    "\n",
    "                            distance_initial_list.append(distance_initial)\n",
    "                            distance_final_list.append(distance_final)\n",
    "\n",
    "#                             print('UCL', date_forecast, '\\t', distance_initial, distance_final)\n",
    "\n",
    "            results[str(time_limit)][cyclone_name]['UCL']['distance_initial'] = np.nanmean(distance_initial_list)\n",
    "            results[str(time_limit)][cyclone_name]['UCL']['distance_final'] = np.nanmean(distance_final_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate errors averaging over all the times considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['average_time'] = {}\n",
    "\n",
    "for cyclone_name in cyclone_names:\n",
    "    \n",
    "    # Initialise dictionary for the specific cyclone\n",
    "    results['average_time'][cyclone_name] = {}\n",
    "    \n",
    "    # Single models\n",
    "    for model_num in range(results[str(time_limit_list[0])][cyclone_name]['number_models']):\n",
    "        results['average_time'][cyclone_name][str(model_num)] = {}\n",
    "        results['average_time'][cyclone_name][str(model_num)]['distance_final'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name][str(model_num)]['distance_final'] for i in range(len(time_limit_list))])\n",
    "        results['average_time'][cyclone_name][str(model_num)]['distance_initial'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name][str(model_num)]['distance_initial'] for i in range(len(time_limit_list))])\n",
    "    \n",
    "    # Multimodels\n",
    "    results['average_time'][cyclone_name]['multimodel'] = {}\n",
    "    \n",
    "    for s in range(len(selections_names)):\n",
    "        results['average_time'][cyclone_name]['multimodel'][selections_names[s]] = {}\n",
    "        results['average_time'][cyclone_name]['multimodel'][selections_names[s]]['distance_final'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name]['multimodel'][selections_names[s]]['distance_final'] for i in range(len(time_limit_list))])\n",
    "        results['average_time'][cyclone_name]['multimodel'][selections_names[s]]['distance_initial'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name]['multimodel'][selections_names[s]]['distance_initial'] for i in range(len(time_limit_list))])\n",
    "    \n",
    "    # UCL\n",
    "    results['average_time'][cyclone_name]['UCL'] = {}\n",
    "    results['average_time'][cyclone_name]['UCL']['distance_final'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name]['UCL']['distance_final'] for i in range(len(time_limit_list))])\n",
    "    results['average_time'][cyclone_name]['UCL']['distance_initial'] = np.nanmean([results[str(time_limit_list[i])][cyclone_name]['UCL']['distance_initial'] for i in range(len(time_limit_list))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dictionary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dictionary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots single cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_name = 'nesat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors depending on leading times\n",
    "\n",
    "include_average_time = 'y'\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "width = 0.05  # the width of the bars\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    err[str(t)] = []\n",
    "\n",
    "title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "results_t[cyclone_name]['number_models']\n",
    "\n",
    "for s in range(results[time_limit_list_tot[0]][cyclone_name]['number_models']):\n",
    "    labels.append(results[time_limit_list_tot[0]][cyclone_name][str(s)]['model_name'])\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name][str(s)]['distance_final'])\n",
    "        \n",
    "if include_UCL_data == 'y':\n",
    "    labels.append('UCL')\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_final'])\n",
    "        \n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if len(time_limit_list_tot) % 2:\n",
    "    positions = list(range(-int(len(time_limit_list_tot)/2),0))+[0]+list(range(1,int(len(time_limit_list_tot)/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(len(time_limit_list_tot)/2)+0.5,0,1))+list(np.arange(0.5,int(len(time_limit_list_tot)/2),1))\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    rects[str(t)] = ax.bar(x + width*positions[t], err[str(t)], width, label=time_limit_list_tot[t])\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Extreme sync index ('+str(std_dev)+' std dev)');\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "ax.set_xlabel('Models', labelpad = 20)\n",
    "ax.yaxis.grid()\n",
    "ax.legend();\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "ttl.set_position([0.5, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(figures_folder+'error_singlemodels_by_model_'+cyclone_name+'.pdf', format='pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors depending on leading times\n",
    "\n",
    "include_average_time = 'y'\n",
    "\n",
    "plt.rcParams['font.size'] = 25\n",
    "width = 0.07  # the width of the bars\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "model_names = [results[str(time_limit_list[0])][cyclone_name][str(s)]['model_name'] for s in range(results[str(time_limit_list[0])][cyclone_name]['number_models'])]\n",
    "\n",
    "if include_UCL_data == 'y':\n",
    "    tot_selection_len = results[str(time_limit_list[0])][cyclone_name]['number_models']+1\n",
    "    tot_selection_names = model_names+['UCL']\n",
    "else:\n",
    "    tot_selection_len = results[str(time_limit_list[0])][cyclone_name]['number_models']\n",
    "    tot_selection_names = model_names\n",
    "\n",
    "for s in range(tot_selection_len):\n",
    "    err[str(s)] = []\n",
    "\n",
    "title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    labels.append(time_limit_list_tot[t])\n",
    "    for s in range(tot_selection_len):\n",
    "        if s < tot_selection_len-1:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name][str(s)]['distance_final'])\n",
    "        else:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_final'])\n",
    "\n",
    "            \n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if tot_selection_len % 2:\n",
    "    positions = list(range(-int(tot_selection_len/2),0))+[0]+list(range(1,int(tot_selection_len/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(tot_selection_len/2)+0.5,0,1))+list(np.arange(0.5,int(tot_selection_len/2),1))\n",
    "\n",
    "for s in range(tot_selection_len):\n",
    "    rects[str(s)] = ax.bar(x + width*positions[s], err[str(s)], width, label=str(tot_selection_names[s]))\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "ax.set_xlabel('Lead time (hours)', labelpad = 20)\n",
    "ax.yaxis.grid()\n",
    "ax.legend();\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "ttl.set_position([0.5, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(figures_folder+'error_singlemodels_by_leadtime_'+cyclone_name+'.pdf', format='pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors depending on leading times, initial distance\n",
    "\n",
    "include_average_time = 'y'\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "width = 0.05  # the width of the bars\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    err[str(t)] = []\n",
    "\n",
    "title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "results_t[cyclone_name]['number_models']\n",
    "\n",
    "for s in range(results[time_limit_list_tot[0]][cyclone_name]['number_models']):\n",
    "    labels.append(results[time_limit_list_tot[0]][cyclone_name][str(s)]['model_name'])\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name][str(s)]['distance_initial'])\n",
    "        \n",
    "if include_UCL_data == 'y':\n",
    "    labels.append('UCL')\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_initial'])\n",
    "        \n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if len(time_limit_list_tot) % 2:\n",
    "    positions = list(range(-int(len(time_limit_list_tot)/2),0))+[0]+list(range(1,int(len(time_limit_list_tot)/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(len(time_limit_list_tot)/2)+0.5,0,1))+list(np.arange(0.5,int(len(time_limit_list_tot)/2),1))\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    rects[str(t)] = ax.bar(x + width*positions[t], err[str(t)], width, label=time_limit_list_tot[t])\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Extreme sync index ('+str(std_dev)+' std dev)');\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "ax.set_xlabel('Models', labelpad = 20)\n",
    "ax.yaxis.grid()\n",
    "ax.legend();\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "ttl.set_position([0.5, 1.05])\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors depending on leading times\n",
    "\n",
    "include_average_time = 'y'\n",
    "\n",
    "plt.rcParams['font.size'] = 30\n",
    "width = 0.05  # the width of the bars\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    err[str(t)] = []\n",
    "\n",
    "title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "\n",
    "for s in range(len(selections_names)):\n",
    "    labels.append(selections_names[s])\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name]['multimodel'][selections_names[s]]['distance_final'])\n",
    "        \n",
    "if include_UCL_data == 'y':\n",
    "    labels.append('UCL')\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        err[str(t)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_final'])\n",
    "        \n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if len(time_limit_list_tot) % 2:\n",
    "    positions = list(range(-int(len(time_limit_list_tot)/2),0))+[0]+list(range(1,int(len(time_limit_list_tot)/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(len(time_limit_list_tot)/2)+0.5,0,1))+list(np.arange(0.5,int(len(time_limit_list_tot)/2),1))\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    rects[str(t)] = ax.bar(x + width*positions[t], err[str(t)], width, label=time_limit_list_tot[t])\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Extreme sync index ('+str(std_dev)+' std dev)');\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "ax.set_xlabel('Models', labelpad = 20)\n",
    "ax.yaxis.grid()\n",
    "ax.legend();\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "ttl.set_position([0.5, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(figures_folder+'error_multimodels_by_model_'+cyclone_name+'.pdf', format='pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors depending on leading times\n",
    "\n",
    "include_average_time = 'y'\n",
    "\n",
    "plt.rcParams['font.size'] = 25\n",
    "width = 0.08  # the width of the bars\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "if include_UCL_data == 'y':\n",
    "    tot_selection_len = len(selections_names)+1\n",
    "    tot_selection_names = selections_names+['UCL']\n",
    "else:\n",
    "    tot_selection_len = len(selections_names)\n",
    "    tot_selection_names = selections_names\n",
    "\n",
    "for s in range(tot_selection_len):\n",
    "    err[str(s)] = []\n",
    "\n",
    "title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    labels.append(time_limit_list_tot[t])\n",
    "    for s in range(tot_selection_len):\n",
    "        if s < tot_selection_len-1:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name]['multimodel'][selections_names[s]]['distance_final'])\n",
    "        else:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_final'])\n",
    "\n",
    "            \n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if tot_selection_len % 2:\n",
    "    positions = list(range(-int(tot_selection_len/2),0))+[0]+list(range(1,int(tot_selection_len/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(tot_selection_len/2)+0.5,0,1))+list(np.arange(0.5,int(tot_selection_len/2),1))\n",
    "\n",
    "for s in range(tot_selection_len):\n",
    "    rects[str(s)] = ax.bar(x + width*positions[s], err[str(s)], width, label=str(tot_selection_names[s]))\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "ax.set_xlabel('Lead time (hours)', labelpad = 20)\n",
    "ax.yaxis.grid()\n",
    "ax.legend();\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "ttl.set_position([0.5, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(figures_folder+'error_multimodels_by_leadtime_'+cyclone_name+'.pdf', format='pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicyclone plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several panels\n",
    "\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "Tot = len(cyclone_names)\n",
    "Cols = 3\n",
    "\n",
    "# Compute Rows required\n",
    "\n",
    "Rows = Tot // Cols \n",
    "Rows += Tot % Cols\n",
    "\n",
    "# Create a Position index\n",
    "\n",
    "Position = range(1,Tot + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(30,50))\n",
    "\n",
    "for k in range(Tot):\n",
    "    \n",
    "    cyclone_name = cyclone_names[k]\n",
    "\n",
    "    # add every single subplot to the figure with a for loop\n",
    "    ax = fig.add_subplot(Rows,Cols,Position[k])\n",
    "  \n",
    "    labels = []\n",
    "    err = {}\n",
    "    rects = {}\n",
    "\n",
    "    if include_average_time == 'y':\n",
    "        time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "    else:\n",
    "        time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "    if include_UCL_data == 'y':\n",
    "        tot_selection_len = len(selections_names)+1\n",
    "        tot_selection_names = selections_names+['UCL']\n",
    "    else:\n",
    "        tot_selection_len = len(selections_names)\n",
    "        tot_selection_names = selections_names\n",
    "\n",
    "    for s in range(tot_selection_len):\n",
    "        err[str(s)] = []\n",
    "\n",
    "    title_string = 'Cyclone: '+cyclone_name\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "\n",
    "    for t in range(len(time_limit_list_tot)):\n",
    "        labels.append(time_limit_list_tot[t])\n",
    "        for s in range(tot_selection_len):\n",
    "            if s < tot_selection_len-1:\n",
    "                err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name]['multimodel'][selections_names[s]]['distance_final'])\n",
    "            else:\n",
    "                err[str(s)].append(results[time_limit_list_tot[t]][cyclone_name]['UCL']['distance_final'])\n",
    "\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "    if tot_selection_len % 2:\n",
    "        positions = list(range(-int(tot_selection_len/2),0))+[0]+list(range(1,int(tot_selection_len/2)+1))\n",
    "    else:\n",
    "        positions = list(np.arange(-int(tot_selection_len/2)+0.5,0,1))+list(np.arange(0.5,int(tot_selection_len/2),1))\n",
    "\n",
    "    for s in range(tot_selection_len):\n",
    "        rects[str(s)] = ax.bar(x + width*positions[s], err[str(s)], width, label=str(tot_selection_names[s]))        \n",
    "        \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    if k % Cols == 0:\n",
    "        ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "    \n",
    "    if any(k==kk for kk in [Tot-1,Tot-2,Tot-3]):\n",
    "        ax.set_xlabel('Lead time (hours)', labelpad = 20)\n",
    "    \n",
    "    ax.yaxis.grid()\n",
    "    \n",
    "    if k == Tot-1:\n",
    "        ax.legend();\n",
    "\n",
    "    ttl = ax.set_title(title_string, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.show()\n",
    "# plt.tight_layout(pad = 1.5, w_pad = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create multicyclone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "\n",
    "for t in time_limit_list_tot:\n",
    "    results[t]['multimodel'] = {}\n",
    "    for s in range(len(selections_names)):\n",
    "        r = []\n",
    "        for cyclone_name in cyclone_names:\n",
    "            r.append(results[t][cyclone_name]['multimodel'][selections_names[s]]['distance_final'])\n",
    "        results[t]['multimodel'][selections_names[s]] = {}\n",
    "        r = np.array(r)\n",
    "        results[t]['multimodel'][selections_names[s]]['distance_final'] = r[~np.isnan(r)]\n",
    "        \n",
    "    r = []\n",
    "    for cyclone_name in cyclone_names:\n",
    "        r.append(results[t][cyclone_name]['UCL']['distance_final'])\n",
    "    results[t]['UCL'] = {}\n",
    "    r = np.array(r)\n",
    "    results[t]['UCL']['distance_final'] = r[~np.isnan(r)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections_better_names = ['KWBC', 'RJTD', 'EGRR', 'ECMWF', 'KWBC + RJTD + EGRR + ECMWF', 'KWBC + EGRR + ECMWF', 'KWBC + RJTD + ECMWF', 'KWBC + ECMWF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 15\n",
    "width = 0.08\n",
    "include_average_time = 'y'\n",
    "\n",
    "colors = ['#ED254E','#F9DC5C','#97EAD2','#731963','#40F99B','#A020F0','#D2691E','#00008B','#FF8C00','#ADFF2F','#FFFF00']\n",
    "colors = ['#8c510a','#bf812d','#dfc27d','#f6e8c3','#f5f5f5','#c7eae5','#80cdc1','#35978f','#01665e']\n",
    "# '#FF3864','#FF00FF','#556B2F','#B8860B',\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "labels = []\n",
    "err = {}\n",
    "rects = {}\n",
    "\n",
    "if include_average_time == 'y':\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]+['average_time']\n",
    "else:\n",
    "    time_limit_list_tot = [str(x) for x in time_limit_list]\n",
    "\n",
    "if include_UCL_data == 'y':\n",
    "    tot_selection_len = len(selections_better_names)+1\n",
    "    tot_selection_names = selections_better_names+['UCL']\n",
    "else:\n",
    "    tot_selection_len = len(selections_better_names)\n",
    "    tot_selection_names = selections_better_names\n",
    "\n",
    "for s in range(tot_selection_len):\n",
    "    err[str(s)] = []\n",
    "\n",
    "title_string = 'Multicyclone ('+str(len(cyclone_names))+' cyclones)'\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(30,12))\n",
    "\n",
    "\n",
    "for t in range(len(time_limit_list_tot)):\n",
    "    labels.append(time_limit_list_tot[t])\n",
    "    for s in range(tot_selection_len):\n",
    "        if s < tot_selection_len-1:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]]['multimodel'][selections_names[s]]['distance_final'])\n",
    "        else:\n",
    "            err[str(s)].append(results[time_limit_list_tot[t]]['UCL']['distance_final'])\n",
    "\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "if tot_selection_len % 2:\n",
    "    positions = list(range(-int(tot_selection_len/2),0))+[0]+list(range(1,int(tot_selection_len/2)+1))\n",
    "else:\n",
    "    positions = list(np.arange(-int(tot_selection_len/2)+0.5,0,1))+list(np.arange(0.5,int(tot_selection_len/2),1))\n",
    "    \n",
    "# Order selection by median of average times\n",
    "selection_ordered = sorted(zip([np.median(err[str(s)][-1]) for s in range(tot_selection_len)], list(range(tot_selection_len))))\n",
    "selection_ordered = [x[1] for x in selection_ordered]\n",
    "\n",
    "for i,s in enumerate(selection_ordered):\n",
    "    rects[str(s)] = ax.boxplot(err[str(s)], positions = x + width*positions[i], widths = width*0.7, patch_artist=True)\n",
    "    \n",
    "    r = random.random()\n",
    "    b = random.random()\n",
    "    g = random.random()\n",
    "    c = (r, g, b)\n",
    "    c = colors[i]\n",
    "    \n",
    "#     for item in ['whiskers', 'fliers', 'medians', 'caps']:\n",
    "#             plt.setp(rects[str(s)][item], color=c)\n",
    "            \n",
    "    plt.setp(rects[str(s)]['medians'], color='black')\n",
    "    plt.setp(rects[str(s)][\"boxes\"], facecolor=c)\n",
    "    plt.setp(rects[str(s)][\"fliers\"], markeredgecolor=c)\n",
    "    \n",
    "#     rects[str(s)]['boxes'].set_facecolor('blue')\n",
    "\n",
    "#         bplot1 = ax1.boxplot(all_data,\n",
    "#                      vert=True,  # vertical box alignment\n",
    "#                      patch_artist=True,  # fill with color\n",
    "#                      labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "#         boxplot(A, positions = [1, 2], widths = 0.6)\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "ax.set_ylabel('Error (km)', labelpad = 20)\n",
    "\n",
    "ax.set_ylim([-10,700])\n",
    "\n",
    "ax.set_xlabel('Lead time (hours)', labelpad = 20)\n",
    "\n",
    "ax.yaxis.grid()\n",
    "\n",
    "ax.legend([rects[str(s)][\"boxes\"][0] for s in selection_ordered], [tot_selection_names[s] for s in selection_ordered], loc='upper right')\n",
    "\n",
    "ttl = ax.set_title(title_string, fontweight='bold')\n",
    "\n",
    "# plt.show()\n",
    "# plt.tight_layout(pad = 1.5, w_pad = 15)\n",
    "# fig.savefig(figures_folder+'error_multicyclone_by_leadtime.pdf', format='pdf', bbox_inches = 'tight', pad_inches = 0.3)\n",
    "# fig.savefig(figures_folder+'error_multicyclone_by_leadtime.png', format='png', dpi=300, bbox_inches = 'tight', pad_inches = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print length data vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cyclone_name in cyclone_names:\n",
    "    print('\\n')\n",
    "    for s in range(results[time_limit_list_tot[0]][cyclone_name]['number_models']):\n",
    "        try:\n",
    "            print(results[time_limit_list_tot[0]][cyclone_name][str(s)]['model_name'], results[time_limit_list_tot[0]][cyclone_name][str(s)][str(0)]['num_members_ensemble'])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_3]",
   "language": "python",
   "name": "conda-env-python_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
